{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM/aP+1KWWbCVXYVTmfbX1w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"Y6ZFhgXpSDA3","executionInfo":{"status":"ok","timestamp":1759213649869,"user_tz":-540,"elapsed":43,"user":{"displayName":"김다예","userId":"15306916753257259362"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn import datasets, metrics\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["# 1. 데이터 로드 & 전처리\n","digits = datasets.load_digits()\n","X_img = digits.images.astype(\"float32\") / 16.0   # 원래 픽셀 범위 0~16 → 0~1 스케일링\n","y = digits.target\n","num_classes = len(np.unique(y))"],"metadata":{"id":"uI9612-wSMzy","executionInfo":{"status":"ok","timestamp":1759213649876,"user_tz":-540,"elapsed":5,"user":{"displayName":"김다예","userId":"15306916753257259362"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# CNN용 채널 차원 추가, MLP용 평탄화는 모델에서 처리\n","X_cnn = X_img[..., np.newaxis]  # (n, 8, 8, 1)\n","y_cat = to_categorical(y, num_classes)"],"metadata":{"id":"0YGkyLMGSM-c","executionInfo":{"status":"ok","timestamp":1759213649877,"user_tz":-540,"elapsed":5,"user":{"displayName":"김다예","userId":"15306916753257259362"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 데이터 분할\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_cnn, y_cat, test_size=0.2, random_state=42, stratify=y\n",")"],"metadata":{"id":"t1B6cVpqSSX_","executionInfo":{"status":"ok","timestamp":1759213649889,"user_tz":-540,"elapsed":16,"user":{"displayName":"김다예","userId":"15306916753257259362"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 2. 모델 선택\n","MODEL = \"mlp\"  # \"mlp\" 혹은 \"cnn\"\n","\n","if MODEL == \"mlp\":\n","    # MLP: 8x8 이미지를 Flatten해서 Dense로 분류\n","    model = models.Sequential([\n","        layers.Input(shape=(8, 8, 1)),\n","        layers.Flatten(),\n","        layers.Dense(128, activation=\"relu\"),\n","        layers.Dropout(0.2),\n","        layers.Dense(64, activation=\"relu\"),\n","        layers.Dense(num_classes, activation=\"softmax\")\n","    ])\n","elif MODEL == \"cnn\":\n","    # 작은 CNN: Conv → Pool → Dense\n","    model = models.Sequential([\n","        layers.Input(shape=(8, 8, 1)),\n","        layers.Conv2D(16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","        layers.MaxPooling2D(),\n","        layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","        layers.GlobalAveragePooling2D(),\n","        layers.Dense(32, activation=\"relu\"),\n","        layers.Dense(num_classes, activation=\"softmax\")\n","    ])\n","else:\n","    raise ValueError(\"MODEL 은 'mlp' 또는 'cnn' 중 하나여야 합니다.\")"],"metadata":{"id":"UTZJHN9vSjtF","executionInfo":{"status":"ok","timestamp":1759213650004,"user_tz":-540,"elapsed":20,"user":{"displayName":"김다예","userId":"15306916753257259362"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 3. 컴파일 & 학습\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","es = EarlyStopping(monitor=\"val_accuracy\", patience=10, restore_best_weights=True)\n","history = model.fit(\n","    X_train, y_train,\n","    validation_split=0.2,\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[es],\n","    verbose=1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEjhfZyRSlVf","executionInfo":{"status":"ok","timestamp":1759213659440,"user_tz":-540,"elapsed":9434,"user":{"displayName":"김다예","userId":"15306916753257259362"}},"outputId":"8f71c33e-20b3-4ff4-b2f4-18539b60f30e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.2434 - loss: 2.1713 - val_accuracy: 0.7674 - val_loss: 1.5747\n","Epoch 2/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 1.3543 - val_accuracy: 0.8681 - val_loss: 0.7946\n","Epoch 3/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.6679 - val_accuracy: 0.8993 - val_loss: 0.4480\n","Epoch 4/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.4525 - val_accuracy: 0.9201 - val_loss: 0.3386\n","Epoch 5/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.3577 - val_accuracy: 0.9236 - val_loss: 0.2756\n","Epoch 6/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.2919 - val_accuracy: 0.9132 - val_loss: 0.2540\n","Epoch 7/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.2206 - val_accuracy: 0.9410 - val_loss: 0.2081\n","Epoch 8/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.2104 - val_accuracy: 0.9375 - val_loss: 0.2100\n","Epoch 9/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9417 - loss: 0.1924 - val_accuracy: 0.9514 - val_loss: 0.1764\n","Epoch 10/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.1472 - val_accuracy: 0.9479 - val_loss: 0.1634\n","Epoch 11/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.1316 - val_accuracy: 0.9583 - val_loss: 0.1433\n","Epoch 12/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.1175 - val_accuracy: 0.9653 - val_loss: 0.1390\n","Epoch 13/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9765 - loss: 0.1159 - val_accuracy: 0.9583 - val_loss: 0.1319\n","Epoch 14/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9661 - loss: 0.1116 - val_accuracy: 0.9618 - val_loss: 0.1351\n","Epoch 15/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1029 - val_accuracy: 0.9583 - val_loss: 0.1356\n","Epoch 16/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.1104 - val_accuracy: 0.9618 - val_loss: 0.1268\n","Epoch 17/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0770 - val_accuracy: 0.9549 - val_loss: 0.1193\n","Epoch 18/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0747 - val_accuracy: 0.9583 - val_loss: 0.1228\n","Epoch 19/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0651 - val_accuracy: 0.9688 - val_loss: 0.1040\n","Epoch 20/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0677 - val_accuracy: 0.9653 - val_loss: 0.1055\n","Epoch 21/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9737 - loss: 0.0703 - val_accuracy: 0.9618 - val_loss: 0.1114\n","Epoch 22/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0581 - val_accuracy: 0.9653 - val_loss: 0.1087\n","Epoch 23/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0567 - val_accuracy: 0.9618 - val_loss: 0.1146\n","Epoch 24/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.0729 - val_accuracy: 0.9583 - val_loss: 0.1001\n","Epoch 25/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0404 - val_accuracy: 0.9653 - val_loss: 0.1090\n","Epoch 26/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0404 - val_accuracy: 0.9653 - val_loss: 0.1094\n","Epoch 27/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0401 - val_accuracy: 0.9688 - val_loss: 0.1015\n","Epoch 28/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0501 - val_accuracy: 0.9722 - val_loss: 0.0975\n","Epoch 29/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0307 - val_accuracy: 0.9583 - val_loss: 0.1133\n","Epoch 30/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0300 - val_accuracy: 0.9722 - val_loss: 0.0927\n","Epoch 31/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0488 - val_accuracy: 0.9618 - val_loss: 0.0930\n","Epoch 32/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0347 - val_accuracy: 0.9618 - val_loss: 0.1005\n","Epoch 33/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0355 - val_accuracy: 0.9618 - val_loss: 0.1100\n","Epoch 34/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9898 - loss: 0.0370 - val_accuracy: 0.9618 - val_loss: 0.0959\n","Epoch 35/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0294 - val_accuracy: 0.9583 - val_loss: 0.1048\n","Epoch 36/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0280 - val_accuracy: 0.9688 - val_loss: 0.1082\n","Epoch 37/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0295 - val_accuracy: 0.9688 - val_loss: 0.0949\n","Epoch 38/100\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0238 - val_accuracy: 0.9722 - val_loss: 0.1036\n"]}]},{"cell_type":"code","source":["# 4. 평가\n","test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"[{MODEL.upper()}] Test Accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hEWIwLE-SnXL","executionInfo":{"status":"ok","timestamp":1759213659518,"user_tz":-540,"elapsed":76,"user":{"displayName":"김다예","userId":"15306916753257259362"}},"outputId":"21fd2a53-0c48-46db-f93b-286f35bae82e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[MLP] Test Accuracy: 0.9806\n"]}]},{"cell_type":"code","source":["# 5. 추가 지표 (혼동행렬, 분류 리포트)\n","y_pred_prob = model.predict(X_test, verbose=0)\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","y_true = np.argmax(y_test, axis=1)\n","\n","print(\"\\nClassification Report\")\n","print(metrics.classification_report(y_true, y_pred, digits=4))\n","\n","print(\"Confusion Matrix\")\n","print(metrics.confusion_matrix(y_true, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgL9t90NSpQR","executionInfo":{"status":"ok","timestamp":1759213659739,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다예","userId":"15306916753257259362"}},"outputId":"63754364-e7aa-484e-94bc-452562ec4632"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Classification Report\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000        36\n","           1     0.9211    0.9722    0.9459        36\n","           2     1.0000    1.0000    1.0000        35\n","           3     1.0000    0.9730    0.9863        37\n","           4     1.0000    1.0000    1.0000        36\n","           5     0.9487    1.0000    0.9737        37\n","           6     1.0000    0.9722    0.9859        36\n","           7     0.9730    1.0000    0.9863        36\n","           8     0.9688    0.8857    0.9254        35\n","           9     1.0000    1.0000    1.0000        36\n","\n","    accuracy                         0.9806       360\n","   macro avg     0.9811    0.9803    0.9804       360\n","weighted avg     0.9811    0.9806    0.9804       360\n","\n","Confusion Matrix\n","[[36  0  0  0  0  0  0  0  0  0]\n"," [ 0 35  0  0  0  1  0  0  0  0]\n"," [ 0  0 35  0  0  0  0  0  0  0]\n"," [ 0  0  0 36  0  1  0  0  0  0]\n"," [ 0  0  0  0 36  0  0  0  0  0]\n"," [ 0  0  0  0  0 37  0  0  0  0]\n"," [ 0  0  0  0  0  0 35  0  1  0]\n"," [ 0  0  0  0  0  0  0 36  0  0]\n"," [ 0  3  0  0  0  0  0  1 31  0]\n"," [ 0  0  0  0  0  0  0  0  0 36]]\n"]}]}]}